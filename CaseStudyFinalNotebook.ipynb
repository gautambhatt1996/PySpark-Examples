{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDF(fileformat,fpath):\n",
    "    df=spark.read.format(fileformat)\\\n",
    "            .option(\"header\", True)\\\n",
    "            .option(\"sep\",\",\") \\\n",
    "            .load(fpath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'fformat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bce10b86c4e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchargesdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepareDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchargespath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdamagesdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepareDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdamagespath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mendorsedf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepareDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendorsepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprimarypersondf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepareDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimarypersonpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrestrictdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepareDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestrictpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'fformat'"
     ]
    }
   ],
   "source": [
    "chargesdf=prepareDF(filepath.fformat,filepath.chargespath)\n",
    "damagesdf=prepareDF(filepath.fformat,filepath.damagespath)\n",
    "endorsedf=prepareDF(filepath.fformat,filepath.endorsepath)\n",
    "primarypersondf=prepareDF(filepath.fformat,filepath.primarypersonpath)\n",
    "restrictdf=prepareDF(filepath.fformat,filepath.restrictpath)\n",
    "unitsdf=prepareDF(filepath.fformat,filepath.unitspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of Crashes in which persons killed are male is ', 180)\n"
     ]
    }
   ],
   "source": [
    "##Analytics 1: Find the number of crashes (accidents) in which number of persons killed are male?\n",
    "\n",
    "a1=primarypersondf.filter((primarypersondf.PRSN_GNDR_ID =='MALE') \n",
    "                          & (primarypersondf.PRSN_INJRY_SEV_ID =='KILLED')).select('CRASH_ID').distinct()\n",
    "print('Number of Crashes in which persons killed are male is ',a1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of Two Wheelers booked for crashes are ', 757)\n"
     ]
    }
   ],
   "source": [
    "##Analysis 2: How many two wheelers are booked for crashes?\n",
    "\n",
    "interdf=unitsdf.filter((unitsdf.VEH_BODY_STYL_ID =='MOTORCYCLE') | (unitsdf.VEH_BODY_STYL_ID == 'POLICE MOTORCYCLE'))\n",
    "a2=chargesdf.join(interdf,['CRASH_ID'],'inner').select('CRASH_ID').distinct()\n",
    "print('Number of Two Wheelers booked for crashes are ',a2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state which has highest number of accidents in which females involved is \n",
      "+-----------------+\n",
      "|DRVR_LIC_STATE_ID|\n",
      "+-----------------+\n",
      "|            Texas|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Analysis 3: Which state has highest number of accidents in which females are involved? \n",
    "\n",
    "femaledf=primarypersondf.filter((primarypersondf.PRSN_GNDR_ID =='FEMALE'))\n",
    "a3=femaledf.groupBy('DRVR_LIC_STATE_ID').count().sort(col(\"count\").desc()).select('DRVR_LIC_STATE_ID').limit(1)\n",
    "print('The state which has highest number of accidents in which females involved is ')\n",
    "a3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5th to 15th VEH_MAKE_IDs that contribute to a largest number of injuries including death are\n",
      "+-------------+\n",
      "|Top_5_to_15Th|\n",
      "+-------------+\n",
      "|        HONDA|\n",
      "|       NISSAN|\n",
      "|          GMC|\n",
      "|         JEEP|\n",
      "|      HYUNDAI|\n",
      "|     CHRYSLER|\n",
      "|          KIA|\n",
      "|        MAZDA|\n",
      "|      PONTIAC|\n",
      "|        LEXUS|\n",
      "|        BUICK|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Analysis 4: Which are the Top 5th to 15th VEH_MAKE_IDs that contribute to a \n",
    "##largest number of injuries including death\n",
    "\n",
    "crashdf=primarypersondf.filter(col('PRSN_INJRY_SEV_ID')\n",
    "                               .isin(['NA','UNKNOWN','NOT INJURED']) == False).select('CRASH_ID').distinct()\n",
    "joineddf=crashdf.join(unitsdf,['CRASH_ID'],'left').drop_duplicates(subset = ['CRASH_ID'])\n",
    "\n",
    "df=joineddf.groupBy('VEH_MAKE_ID').count().sort(col(\"count\").desc())\n",
    "def getrows(df, rownums=None):\n",
    "    return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: x[0])\n",
    "\n",
    "a=getrows(df, rownums=[i for i in range(4,15)])\n",
    "schema = StructType([StructField(\"VEH_MAKE_ID\", StringType()),\n",
    "                     StructField(\"count\", IntegerType())])\n",
    "df2 = sqlContext.createDataFrame(a, schema) \n",
    "a4=df2.selectExpr(\"VEH_MAKE_ID as Top_5_to_15Th\")\n",
    "print('The top 5th to 15th VEH_MAKE_IDs that contribute to a largest number of injuries including death are')\n",
    "a4.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top ethnic user group of each unique body style are:\n",
      "+---------------------------------+-----------------+\n",
      "|VEH_BODY_STYL_ID                 |PRSN_ETHNICITY_ID|\n",
      "+---------------------------------+-----------------+\n",
      "|BUS                              |HISPANIC         |\n",
      "|VAN                              |WHITE            |\n",
      "|PICKUP                           |WHITE            |\n",
      "|SPORT UTILITY VEHICLE            |WHITE            |\n",
      "|PASSENGER CAR, 4-DOOR            |WHITE            |\n",
      "|FIRE TRUCK                       |WHITE            |\n",
      "|TRUCK                            |WHITE            |\n",
      "|UNKNOWN                          |WHITE            |\n",
      "|AMBULANCE                        |WHITE            |\n",
      "|POLICE CAR/TRUCK                 |WHITE            |\n",
      "|MOTORCYCLE                       |WHITE            |\n",
      "|YELLOW SCHOOL BUS                |WHITE            |\n",
      "|POLICE MOTORCYCLE                |HISPANIC         |\n",
      "|PASSENGER CAR, 2-DOOR            |WHITE            |\n",
      "|TRUCK TRACTOR                    |WHITE            |\n",
      "|FARM EQUIPMENT                   |WHITE            |\n",
      "|NEV-NEIGHBORHOOD ELECTRIC VEHICLE|WHITE            |\n",
      "|OTHER  (EXPLAIN IN NARRATIVE)    |WHITE            |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Analysis 5: For all the body styles involved in crashes, mention the top ethnic user group of each unique body styleÂ \n",
    "\n",
    "joindf=unitsdf.join(primarypersondf,['CRASH_ID'],'left')\n",
    "testdf=joindf.filter((col('PRSN_ETHNICITY_ID')\n",
    "                               .isin(['NA','UNKNOWN']) == False) & (col('VEH_BODY_STYL_ID')\n",
    "                               .isin(['NOT REPORTED','NA']) == False))\\\n",
    "                               .groupBy('VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID').count()\n",
    "\n",
    "ranked =testdf.withColumn(\"rank\", dense_rank().over(Window.partitionBy(\"VEH_BODY_STYL_ID\").orderBy(desc(\"count\"))))\n",
    "a5=ranked.filter(col('rank').isin([1]) == True).select('VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID')\n",
    "print('The top ethnic user group of each unique body style are:')\n",
    "a5.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Zip Codes with highest number crashes with alcohols as the contributing factor to a crash are\n",
      "+--------+\n",
      "|DRVR_ZIP|\n",
      "+--------+\n",
      "|   78521|\n",
      "|   76010|\n",
      "|   79936|\n",
      "|   79938|\n",
      "|   79907|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 6: Among the crashed cars, what are the Top 5 Zip Codes \n",
    "#with highest number crashes with alcohols as the contributing factor to a crash (Use Driver Zip Code)\n",
    "\n",
    "a6=primarypersondf.filter((col('PRSN_ALC_RSLT_ID').isin(['Positive']) == True) & (col('DRVR_ZIP')\n",
    "                               .isin(['null']) == False)).groupBy('DRVR_ZIP').count().sort(col(\"count\").desc())\\\n",
    "                               .select('DRVR_ZIP')\n",
    "print('Top 5 Zip Codes with highest number crashes with alcohols as the contributing factor to a crash are')\n",
    "a6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Count of Distinct Crash IDs where No Damaged Property was observed and Damage       Level is above 4 and car avails Insurance is', 8415)\n"
     ]
    }
   ],
   "source": [
    "#Analysis 7: Count of Distinct Crash IDs where No Damaged Property was observed and Damage Level \n",
    "#(VEH_DMAG_SCL~) is above 4 and car avails Insurance\n",
    "\n",
    "filteredunitdf=unitsdf.filter((col('VEH_DMAG_SCL_1_ID').isin(['DAMAGED 5','DAMAGED 6','DAMAGED 7 HIGHEST']) == True) & \n",
    "              (col('FIN_RESP_TYPE_ID').isin(['NA']) == False))\n",
    "a7=filteredunitdf.join(damagesdf, [\"CRASH_ID\"], \"leftanti\").select('CRASH_ID').distinct()\n",
    "print('Count of Distinct Crash IDs where No Damaged Property was observed and Damage\\\n",
    "      Level is above 4 and car avails Insurance is',a7.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Vehicle Makes where drivers are charged with speeding related offences,has licensed Drivers,      uses top 10 used vehicle colours and has car licensed with the Top 25 states with highest number      of offences are\n",
      "+-----------+\n",
      "|VEH_MAKE_ID|\n",
      "+-----------+\n",
      "|       FORD|\n",
      "|  CHEVROLET|\n",
      "|     TOYOTA|\n",
      "|      DODGE|\n",
      "|     NISSAN|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 8: Determine the Top 5 Vehicle Makes where drivers are charged with speeding related offences, \n",
    "#has licensed Drivers, uses top 10 used vehicle colours and has car licensed with the Top 25 states with \n",
    "#highest number of offences (to be deduced from the data)\n",
    "\n",
    "df1=chargesdf.filter(chargesdf[\"CHARGE\"].contains('SPEED'))\n",
    "df2=primarypersondf.filter((col('DRVR_LIC_TYPE_ID').isin(['COMMERCIAL DRIVER LIC.','ID CARD','OCCUPATIONAL',\n",
    "                                                          'DRIVER LICENSE'])) == True)\n",
    "df3=unitsdf.groupBy('VEH_COLOR_ID').count().sort(col(\"count\").desc())\\\n",
    "            .filter(col('VEH_COLOR_ID').isin(['NA']) ==False).select('VEH_COLOR_ID').limit(10)\n",
    "df4=primarypersondf.groupBy('DRVR_LIC_STATE_ID').count().sort(col(\"count\")\\\n",
    "                    .desc()).filter(col('DRVR_LIC_STATE_ID').isin(['NA','Other','Unknown']) ==False).limit(25)\n",
    "\n",
    "joindata=df1.join(unitsdf,['CRASH_ID'],'left')\n",
    "joindata=joindata.join(df2,['CRASH_ID'],'left')\n",
    "\n",
    "joindata=joindata.na.drop(subset = ['DRVR_LIC_TYPE_ID','CHARGE'])\n",
    "\n",
    "newdf=df3.join(joindata,['VEH_COLOR_ID'],'left')\n",
    "newdf=df4.join(newdf,['DRVR_LIC_STATE_ID'],'left')\n",
    "a8=newdf.groupBy('VEH_MAKE_ID').count().sort(col(\"count\").desc()).select('VEH_MAKE_ID')\n",
    "print('Top 5 Vehicle Makes where drivers are charged with speeding related offences,has licensed Drivers,\\\n",
    "      uses top 10 used vehicle colours and has car licensed with the Top 25 states with highest number\\\n",
    "      of offences are')\n",
    "a8.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
